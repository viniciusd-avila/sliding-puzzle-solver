#+Title: Projetos Finais EDA - A2

Data entrega das notas 28/06/2018. 
Data entraga dos trabalhos pelos alunos: 28 (manhã).

Eu poderei acompanhar os repositórios se os alunos me escreverem
pedindo suporte.

Qualquer implementação extra dos projetos indo além dos pedidos
abaixo, será considerada na nota!

Todos os projetos devem ser acompanhados de um relatório, feito
preferencialmente em LaTeX, contendo:

1. documentação de como usar o código e documentaçõa de cada função
   implementada; explicação sobre como o trabalho foi feito,
   dificuldades e como as soluções foram encontradas. 

2. Uma auto-avaliação do aluno no curso.

* Projeto 1: pesquisa de mútiplos padrões em textos

O material deste projeto encontra-se no diretório =cpdoc=. As
sentenças já estão 'parseadas' nos arquivos conllu que podem ser lidos
com a biblioteca =cl-conllu= disponível via http://quicklisp.org.

#+BEGIN_EXAMPLE
CL-USER> (ql:quickload :cl-conllu)
To load "cl-conllu":
  Load 1 ASDF system:
    cl-conllu
; Loading "cl-conllu"
.
; "wilbur:base;" = /.../quicklisp/software/de.setf.wilbur-20171227-git/
...
(:CL-CONLLU)
CL-USER> (let ((sents (cl-conllu:read-conllu "cpdoc/data/")))
	   (length sents))
726
#+END_EXAMPLE

Os 'nomes' de pessoas e organizações que devem ser localizados nas
sentenças estão nos arquivos =cpdoc/*.txt=.  Os arquivos finais para
análise com todas as sentenças do DHBB, depois que o algorítmo estiver
pronto, estão no diretório =udp= do repositório
https://github.com/cpdoc/dhbb-nlp.

A documentação sobre a biblioteca cl-conllu está no wiki do
repositório em https://github.com/own-pt/cl-conllu.

Tarefas:

1. Contar quantidade de ocorrências de cada nome de pessoa e
   organização nas sentenças. Também deve haver uma função para
   inspecionar as contagens, isto é, dado um nome, listar todas as
   sentenças (indicando o arquivo conllu de origem) que contém aquele
   nome.

2. Deseja-se uma solução que execute apenas uma passada linear pelas
   sentenças. Além do apresentado em sala, parte do curso
   https://www.coursera.org/learn/algorithms-on-strings, outras
   abordagens descritas na [[https://en.m.wikipedia.org/wiki/String_searching_algorithm#Algorithms_using_a_finite_set_of_patterns][Wikipedia]] podem ser usadas.

3. Na lista de nomes, podem haver nomes que são substrings de outros
   nomes: Fernando Gomes Oliveira e Fernando Gomes. Neste caso, os
   ambos devem ser contados e obviamente as substrings devem ter
   sempre a contagem superior.

4. Usando os arquivos conllu e a biblioteca cl-conllu, estaremos
   exercitando a abordagem 'token-based', isto é, ao invés da busca
   nas strings ser por caracteres, estaremos buscando por tokens. Uma
   discussão sobre a diferença de abordar o problema da forma
   char-based vs token-based é parte do trabalho. 

5. Como lidar com contrações? Pode-se pre-processar as listas de
   nomes, removendo as contrações (ex: do ~> de o) ou tratar de forma
   mais esperta a recuperação da lista de 'tokens' das sentenças,
   considerando o objetivo mtoken além de apenas listar os tokens de
   cada sentença.

* Projeto 2: projetos curso Princeton

Qualquer projeto listado no curso de Princeton poderá ser considerado:

http://www.cs.princeton.edu/courses/archive/spring18/cos226/assignments.php

Em especial, indico o projeto da [[http://www.cs.princeton.edu/courses/archive/spring18/cos226/assignments/wordnet/index.html][Wordnet]].

O projeto [[http://www.cs.princeton.edu/courses/archive/spring18/cos226/assignments/autocomplete/index.html][autocomplete]] também pode ser feito, a parte mais delicada
seria como usar a interface sugerida que ilustra o funcionamento do
autocomplete. Possiveis alternativas:

1. Usar o ABCL (https://common-lisp.net/project/armedbear/) que
   permite interoperabilidade de Lisp com Java. Obviamente também
   daria para fazer isso com Clojure
   (https://clojure.org/guides/learn/syntax) mas ai estamos falando de
   outra linguagem que não é CL.

2. Usar Web! Desenvolver alguma interface WEB mínima que interaja com
   seu código Lisp, via javascript.

* Projeto 3: SAT fórmulas

O primeiro passo é a transformação de qq problema SAT, dado em
fórmulas quaisquer, em fórmulas CNF (vide [[https://en.wikipedia.org/wiki/Conjunctive_normal_form#Conversion_into_CNF][Wikipedia]]). Também encontram
o algorítmo no livro [[https://www.amazon.com/Knowledge-Representation-Reasoning-Artificial-Intelligence/dp/1558609326/ref=sr_1_1?ie=UTF8&qid=1529481168][KRR]].

Uma vez a formula estando em CNF, o passo seguinte é a transformação
proposta de SAT para 3SAT em nosso livro texto.

Seria interessante implementar testes de equivalência. Ou seja, como
checar que a formula de entrada é valida se e apenas se a formula
final em 3SAT+CNF também for. Para casos pequenos, uma forma simples
de testar seria verificar se ambas as fórmulas tem tabelas verdade
iguais.

Finalmente, codificar em SAT o problema dos vestidos (neste repo
descrição) e SUDOKU em SAT e executar nestas entradas a transformação
para 3SAT+CNF. Para o problema dos vestidos será possível resolver,
para SUDOKU será mais complicado.

Codificação do problema dos vestidos:

https://github.com/arademaker/krr/blob/master/vestidos.lisp

Codificação em SAT de SUDOKU:

https://github.com/arademaker/krr/blob/master/sudoku.lisp

Exemplo de uso de um SAT solver para resolver SUDOKU:

https://gist.github.com/marnitto/725b59bac12ba1f2afe1822f3b22c6d3

